<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-x32.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-x16.ico"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="veaTBtqt4ArdFO7yL4lECMYJsOeSwdptb1k8vJJBzMA"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:new URL("https://lyreal666.com").hostname,root:"/",scheme:"Pisces",version:"7.7.1",exturl:!0,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!0,style:"default"},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!0,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}}}</script><meta name="description" content="其实爬虫是一个对计算机综合能力要求比较高的技术活。首先是要对网络协议尤其是 http 协议有基本的了解, 能够分析网站的数据请求响应。学会使用一些工具，简单的情况使用 chrome devtools 的 network 面板就够了。我一般还会配合 postman 或者 charles 来分析，更复杂的情况可能举要使用专业的抓包工具比如 wireshark 了。你对一个网站了解的越深，越容易想出简单"><meta property="og:type" content="article"><meta property="og:title" content="使用 nodejs 写爬虫(二): 抓取 github 热门项目"><meta property="og:url" content="https://lyreal666.com/%E4%BD%BF%E7%94%A8-nodejs-%E5%86%99%E7%88%AC%E8%99%AB-%E4%BA%8C-%E6%8A%93%E5%8F%96-github-%E7%83%AD%E9%97%A8%E9%A1%B9%E7%9B%AE/index.html"><meta property="og:site_name" content="余腾靖的博客"><meta property="og:description" content="其实爬虫是一个对计算机综合能力要求比较高的技术活。首先是要对网络协议尤其是 http 协议有基本的了解, 能够分析网站的数据请求响应。学会使用一些工具，简单的情况使用 chrome devtools 的 network 面板就够了。我一般还会配合 postman 或者 charles 来分析，更复杂的情况可能举要使用专业的抓包工具比如 wireshark 了。你对一个网站了解的越深，越容易想出简单"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2019/04/04/5ca59077e7a3e.png"><meta property="og:image" content="https://i.loli.net/2019/04/04/5ca592da2bb41.png"><meta property="og:image" content="https://i.loli.net/2019/04/04/5ca594909a591.png"><meta property="og:image" content="https://i.loli.net/2019/04/04/5ca595318c77b.png"><meta property="og:image" content="https://i.loli.net/2019/04/04/5ca5bb4f43e12.png"><meta property="og:image" content="https://i.loli.net/2019/04/05/5ca71256f4137.png"><meta property="og:image" content="https://i.loli.net/2019/04/05/5ca711441ccb8.png"><meta property="article:published_time" content="2019-04-04T04:12:00.000Z"><meta property="article:modified_time" content="2020-02-06T11:15:39.765Z"><meta property="article:author" content="余腾靖"><meta property="article:tag" content="node"><meta property="article:tag" content="spider"><meta property="article:tag" content="github"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2019/04/04/5ca59077e7a3e.png"><link rel="canonical" href="https://lyreal666.com/%E4%BD%BF%E7%94%A8-nodejs-%E5%86%99%E7%88%AC%E8%99%AB-%E4%BA%8C-%E6%8A%93%E5%8F%96-github-%E7%83%AD%E9%97%A8%E9%A1%B9%E7%9B%AE/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0}</script><title>使用 nodejs 写爬虫(二): 抓取 github 热门项目 | 余腾靖的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="余腾靖的博客" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">余腾靖的博客</span> <span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a></li><li class="menu-item menu-item-links"><a href="/links/" rel="section"><i class="fa fa-fw fa-link"></i>友链</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://lyreal666.com/%E4%BD%BF%E7%94%A8-nodejs-%E5%86%99%E7%88%AC%E8%99%AB-%E4%BA%8C-%E6%8A%93%E5%8F%96-github-%E7%83%AD%E9%97%A8%E9%A1%B9%E7%9B%AE/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.png"><meta itemprop="name" content="余腾靖"><meta itemprop="description" content="总结和分享我的所学所思"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="余腾靖的博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">使用 nodejs 写爬虫(二): 抓取 github 热门项目</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-04-04 12:12:00" itemprop="dateCreated datePublished" datetime="2019-04-04T12:12:00+08:00">2019-04-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-02-06 19:15:39" itemprop="dateModified" datetime="2020-02-06T19:15:39+08:00">2020-02-06</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%90%8E%E7%AB%AF/" itemprop="url" rel="index"><span itemprop="name">后端</span> </a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>其实爬虫是一个对计算机综合能力要求比较高的技术活。</p><p>首先是要对网络协议尤其是 <code>http</code> 协议有基本的了解, 能够分析网站的数据请求响应。学会使用一些工具，简单的情况使用 chrome devtools 的 network 面板就够了。我一般还会配合 postman 或者 charles 来分析，更复杂的情况可能举要使用专业的抓包工具比如 wireshark 了。你对一个网站了解的越深，越容易想出简单的方式来爬取你想获取的信息。</p><p>除了要了解一些计算机网络的知识，你还需要具备一定的字符串处理能力，具体来说就是正则表达式玩的溜，其实正则表达式一般的使用场景下用不到很多高级知识，比较常用的有点小复杂的就是分组，非贪婪匹配等。俗话说，学好正则表达式，处理字符串都不怕 🤣。</p><p>还有就是掌握一些反爬虫技巧，写爬虫你可能会碰到各种各样的问题，但是不要怕，再复杂的 12306 都有人能够爬，还有什么是能难到我们的。常见的爬虫碰到的问题比如服务器会检查 cookies, 检查 host 和 referer 头，表单中有隐藏字段，验证码，访问频率限制，需要代理, spa 网站等等。其实啊，绝大多数爬虫碰到的问题最终都可以通过操纵浏览器爬取的。</p><p>这篇使用 nodejs 写爬虫系列第二篇。实战一个小爬虫，抓取 github 热门项目。想要达到目标:</p><ol><li>学会从网页源代码中提取数据这种最基本的爬虫</li><li>使用 json 文件保存抓取的数据</li><li>熟悉我上一篇介绍的一些模块</li><li>学会 node 中怎样处理用户输入</li></ol><a id="more"></a><h2 id="分析需求"><a href="#分析需求" class="headerlink" title="分析需求"></a>分析需求</h2><p>我们的需求是从 github 上抓取热门项目数据，也就是 star 数排名靠前的项目。但是 github 好像没有哪个页面可以看到排名靠前的项目。<strong>往往网站提供的搜索功能是我们写爬虫的人分析的重点对象</strong>。</p><p>我之前在 v2ex 灌水的时候，看到一个讨论 <code>996</code> 的帖子上刚好教了一个查看 github stars 数前几的仓库的方法。其实很简单，就是在 github 搜索时加上 star 数的过滤条件比如: <code>stars:&gt;60000</code>，就可以搜索到 github 上所有 star 数大于 60000 的仓库。分析下面的截图，注意图片中的注释:</p><p><img data-src="https://i.loli.net/2019/04/04/5ca59077e7a3e.png" alt="github-hot-projects"></p><p>分析一下可以得出以下信息:</p><ol><li>这个搜索结果页面是通过 get 请求返回 html 文档的，因为我 network 选择了 <code>Doc</code> 过滤</li><li>url 中的请求的参数有 3 个，p(page) 代表页面数，q(query) 代表搜索内容，type 代表搜索内容的类型</li></ol><p>然后我又想 github 会不会检查 cookies 和其它请求头比如 referer，host 等，根据是否有这些请求头决定是否返回页面。</p><p><img data-src="https://i.loli.net/2019/04/04/5ca592da2bb41.png" alt="request headers"></p><p>比较简单的测试方法是直接用命令行工具 <code>curl</code> 来测试, 在 gitbash 中输入下面命令即 <code>curl &quot;请求的url&quot;</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl <span class="string">"https://github.com/search?p=2&amp;q=stars%3A%3E60000&amp;type=Repositories"</span></span><br></pre></td></tr></table></figure><p>不出意外的正常的返回了页面的源代码, 这样的话我们的爬虫脚本就不用加上请求头和 cookies 了。</p><p><img data-src="https://i.loli.net/2019/04/04/5ca594909a591.png" alt="gitbash-curl-github"></p><p>通过 chrome 的搜索功能，我们可以看到网页源代码中就有我们需要的项目信息</p><p><img data-src="https://i.loli.net/2019/04/04/5ca595318c77b.png" alt="source code search"></p><p>分析到此结束，这其实就是一个很简单的小爬虫，我们只需要配置好查询参数，通过 http 请求获取到网页源代码，然后利用解析库解析，获取源代码中我们需要的和项目相关的信息，再处理一下数据成数组，最后序列化成 json 字符串存储到到 json 文件中。</p><p><img data-src="https://i.loli.net/2019/04/04/5ca5bb4f43e12.png" alt="postman-github-search"></p><h2 id="动手来实现这个小爬虫"><a href="#动手来实现这个小爬虫" class="headerlink" title="动手来实现这个小爬虫"></a>动手来实现这个小爬虫</h2><h3 id="获取源代码"><a href="#获取源代码" class="headerlink" title="获取源代码"></a>获取源代码</h3><p>想要通过 node 获取源代码，我们需要先配置好 url 参数， 再通过 superagent 这个发送 http 请求的模块来访问配置好的 url。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">'use strict'</span>;</span><br><span class="line"><span class="keyword">const</span> requests = <span class="built_in">require</span>(<span class="string">'superagent'</span>);</span><br><span class="line"><span class="keyword">const</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"><span class="keyword">const</span> constants = <span class="built_in">require</span>(<span class="string">'../config/constants'</span>);</span><br><span class="line"><span class="keyword">const</span> logger = <span class="built_in">require</span>(<span class="string">'../config/log4jsConfig'</span>).log4js.getLogger(<span class="string">'githubHotProjects'</span>);</span><br><span class="line"><span class="keyword">const</span> requestUtil = <span class="built_in">require</span>(<span class="string">'./utils/request'</span>);</span><br><span class="line"><span class="keyword">const</span> models = <span class="built_in">require</span>(<span class="string">'./models'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取 star 数不低于 starCount k 的项目第 page 页的源代码</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param <span class="type">&#123;number&#125;</span> </span>starCount star 数量下限</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param <span class="type">&#123;number&#125;</span> </span>page 页数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">const</span> crawlSourceCode = <span class="keyword">async</span> (starCount, page = <span class="number">1</span>) =&gt; &#123;</span><br><span class="line">  <span class="comment">// 下限为 starCount k star 数</span></span><br><span class="line">  starCount = starCount * <span class="number">1024</span>;</span><br><span class="line">  <span class="comment">// 替换 url 中的参数</span></span><br><span class="line">  <span class="keyword">const</span> url = constants.searchUrl.replace(<span class="string">'$&#123;starCount&#125;'</span>, starCount).replace(<span class="string">'$&#123;page&#125;'</span>, page);</span><br><span class="line">  <span class="comment">// response.text 即为返回的源代码</span></span><br><span class="line">  <span class="keyword">const</span> &#123; <span class="attr">text</span>: sourceCode &#125; = <span class="keyword">await</span> requestUtil.logRequest(requests.get(<span class="built_in">encodeURI</span>(url)));</span><br><span class="line">  <span class="keyword">return</span> sourceCode;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面代码中的 constants 模块是用来保存项目中的一些常量配置的，到时候需要改常量直接改这个配置文件就行了，而且配置信息更集中，便于查看。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">  searchUrl: <span class="string">'https://github.com/search?q=stars:&gt;$&#123;starCount&#125;&amp;p=$&#123;page&#125;&amp;type=Repositories'</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="解析源代码获取项目信息"><a href="#解析源代码获取项目信息" class="headerlink" title="解析源代码获取项目信息"></a>解析源代码获取项目信息</h3><p>这里我把项目信息抽象成了一个 Repository 类了。在项目的 models 目录下的 Repository.js 中。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">'fs-extra'</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">'path'</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = <span class="class"><span class="keyword">class</span> <span class="title">Repository</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">async</span> saveToLocal(repositories, indent = <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="keyword">await</span> fs.writeJSON(path.resolve(__dirname, <span class="string">'../../out/repositories.json'</span>), repositories, &#123; <span class="attr">spaces</span>: indent &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">constructor</span>(&#123; name, author, language, digest, starCount, lastUpdate &#125; = &#123;&#125;) &#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.author = author;</span><br><span class="line">    <span class="keyword">this</span>.language = language;</span><br><span class="line">    <span class="keyword">this</span>.digest = digest;</span><br><span class="line">    <span class="keyword">this</span>.starCount = starCount;</span><br><span class="line">    <span class="keyword">this</span>.lastUpdate = lastUpdate;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  display() &#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`   项目: <span class="subst">$&#123;<span class="keyword">this</span>.name&#125;</span> 作者: <span class="subst">$&#123;<span class="keyword">this</span>.author&#125;</span> 语言: <span class="subst">$&#123;<span class="keyword">this</span>.language&#125;</span> star: <span class="subst">$&#123;<span class="keyword">this</span>.starCount&#125;</span></span></span><br><span class="line"><span class="string">摘要: <span class="subst">$&#123;<span class="keyword">this</span>.digest&#125;</span></span></span><br><span class="line"><span class="string">最后更新: <span class="subst">$&#123;<span class="keyword">this</span>.lastUpdate&#125;</span></span></span><br><span class="line"><span class="string">`</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>解析获取到的源代码我们需要使用 cheerio 这个解析库，使用方式和 jquery 很相似。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取 star 数不低于 starCount k 的项目页表</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param <span class="type">&#123;number&#125;</span> </span>starCount star 数量下限</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param <span class="type">&#123;number&#125;</span> </span>page 页数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">const</span> crawlProjectsByPage = <span class="keyword">async</span> (starCount, page = <span class="number">1</span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">const</span> sourceCode = <span class="keyword">await</span> crawlSourceCode(starCount, page);</span><br><span class="line">  <span class="keyword">const</span> $ = cheerio.load(sourceCode);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 下面 cheerio 如果 jquery 比较熟应该没有障碍, 不熟的话 github 官方仓库可以查看 api, api 并不是很多</span></span><br><span class="line">  <span class="comment">// 查看 elements 面板, 发现每个仓库的信息在一个 li 标签内, 下面的代码时建议打开开发者工具的 elements 面板, 参照着阅读</span></span><br><span class="line">  <span class="keyword">const</span> repositoryLiSelector = <span class="string">'.repo-list-item'</span>;</span><br><span class="line">  <span class="keyword">const</span> repositoryLis = $(repositoryLiSelector);</span><br><span class="line">  <span class="keyword">const</span> repositories = [];</span><br><span class="line">  repositoryLis.each(<span class="function">(<span class="params">index, li</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> $li = $(li);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取带有仓库作者和仓库名的 a 链接</span></span><br><span class="line">    <span class="keyword">const</span> nameLink = $li.find(<span class="string">'h3 a'</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提取出仓库名和作者名</span></span><br><span class="line">    <span class="keyword">const</span> [author, name] = nameLink.text().split(<span class="string">'/'</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取项目摘要</span></span><br><span class="line">    <span class="keyword">const</span> digestP = $($li.find(<span class="string">'p'</span>)[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">const</span> digest = digestP.text().trim();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取语言</span></span><br><span class="line">    <span class="comment">// 先获取类名为 .repo-language-color 的那个 span, 在获取包含语言文字的父 div</span></span><br><span class="line">    <span class="comment">// 这里要注意有些仓库是没有语言的, 是获取不到那个 span 的, language 为空字符串</span></span><br><span class="line">    <span class="keyword">const</span> languageDiv = $li.find(<span class="string">'.repo-language-color'</span>).parent();</span><br><span class="line">    <span class="comment">// 这里注意使用 String.trim() 去除两侧的空白符</span></span><br><span class="line">    <span class="keyword">const</span> language = languageDiv.text().trim();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 star 数量</span></span><br><span class="line">    <span class="keyword">const</span> starCountLinkSelector = <span class="string">'.muted-link'</span>;</span><br><span class="line">    <span class="keyword">const</span> links = $li.find(starCountLinkSelector);</span><br><span class="line">    <span class="comment">// 选择器为 .muted-link 还有可能是那个 issues 链接</span></span><br><span class="line">    <span class="keyword">const</span> starCountLink = $(links.length === <span class="number">2</span> ? links[<span class="number">1</span>] : links[<span class="number">0</span>]);</span><br><span class="line">    <span class="keyword">const</span> starCount = starCountLink.text().trim();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取最后更新时间</span></span><br><span class="line">    <span class="keyword">const</span> lastUpdateElementSelector = <span class="string">'relative-time'</span>;</span><br><span class="line">    <span class="keyword">const</span> lastUpdate = $li</span><br><span class="line">      .find(lastUpdateElementSelector)</span><br><span class="line">      .text()</span><br><span class="line">      .trim();</span><br><span class="line">    <span class="keyword">const</span> repository = <span class="keyword">new</span> models.Repository(&#123;</span><br><span class="line">      name,</span><br><span class="line">      author,</span><br><span class="line">      language,</span><br><span class="line">      digest,</span><br><span class="line">      starCount,</span><br><span class="line">      lastUpdate,</span><br><span class="line">    &#125;);</span><br><span class="line">    repositories.push(repository);</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">return</span> repositories;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>有时候搜索结果是有很多页的，所以我这里又写了一个新的函数用来获取指定页面数量的仓库。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> crawlProjectsByPagesCount = <span class="keyword">async</span> (starCount, pagesCount) =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (pagesCount === <span class="literal">undefined</span>) &#123;</span><br><span class="line">    pagesCount = <span class="keyword">await</span> getPagesCount(starCount);</span><br><span class="line">    logger.warn(<span class="string">`未指定抓取的页面数量, 将抓取所有仓库, 总共<span class="subst">$&#123;pagesCount&#125;</span>页`</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> allRepositories = [];</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> tasks = <span class="built_in">Array</span>.from(&#123; <span class="attr">length</span>: pagesCount &#125;, (ele, index) =&gt; &#123;</span><br><span class="line">    <span class="comment">// 因为页数是从 1 开始的, 所以这里要 i + 1</span></span><br><span class="line">    <span class="keyword">return</span> crawlProjectsByPage(starCount, index + <span class="number">1</span>);</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 Promise.all 来并发操作</span></span><br><span class="line">  <span class="keyword">const</span> resultRepositoriesArray = <span class="keyword">await</span> <span class="built_in">Promise</span>.all(tasks);</span><br><span class="line">  resultRepositoriesArray.forEach(<span class="function"><span class="params">repositories</span> =&gt;</span> allRepositories.push(...repositories));</span><br><span class="line">  <span class="keyword">return</span> allRepositories;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="让爬虫项目更人性化"><a href="#让爬虫项目更人性化" class="headerlink" title="让爬虫项目更人性化"></a>让爬虫项目更人性化</h3><p>只是写个脚本，在代码里面配置参数然后去爬，这有点太简陋了。这里我使用了一个可以同步获取用户输入的库<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Fuc2VraS9yZWFkbGluZS1zeW5j" title="https://github.com/anseki/readline-sync">readline-sync<i class="fa fa-external-link"></i></span>，加了一点用户交互，后续的爬虫教程我可能会考虑使用 electron 来做个简单的界面, 下面是程序的启动代码。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> readlineSync = <span class="built_in">require</span>(<span class="string">'readline-sync'</span>);</span><br><span class="line"><span class="keyword">const</span> &#123; crawlProjectsByPage, crawlProjectsByPagesCount &#125; = <span class="built_in">require</span>(<span class="string">'./crawlHotProjects'</span>);</span><br><span class="line"><span class="keyword">const</span> models = <span class="built_in">require</span>(<span class="string">'./models'</span>);</span><br><span class="line"><span class="keyword">const</span> logger = <span class="built_in">require</span>(<span class="string">'../config/log4jsConfig'</span>).log4js.getLogger(<span class="string">'githubHotProjects'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> main = <span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">  <span class="keyword">let</span> isContinue = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> starCount = readlineSync.questionInt(<span class="string">`输入你想要抓取的 github 上项目的 star 数量下限, 单位(k): `</span>, &#123;</span><br><span class="line">      encoding: <span class="string">'utf-8'</span>,</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">const</span> crawlModes = [<span class="string">'抓取某一页'</span>, <span class="string">'抓取一定数量页数'</span>, <span class="string">'抓取所有页'</span>];</span><br><span class="line">    <span class="keyword">const</span> index = readlineSync.keyInSelect(crawlModes, <span class="string">'请选择一种抓取模式'</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> repositories = [];</span><br><span class="line">    <span class="keyword">switch</span> (index) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span>: &#123;</span><br><span class="line">        <span class="keyword">const</span> page = readlineSync.questionInt(<span class="string">'请输入你要抓取的具体页数: '</span>);</span><br><span class="line">        repositories = <span class="keyword">await</span> crawlProjectsByPage(starCount, page);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span>: &#123;</span><br><span class="line">        <span class="keyword">const</span> pagesCount = readlineSync.questionInt(<span class="string">'请输入你要抓取的页面数量: '</span>);</span><br><span class="line">        repositories = <span class="keyword">await</span> crawlProjectsByPagesCount(starCount, pagesCount);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">3</span>: &#123;</span><br><span class="line">        repositories = <span class="keyword">await</span> crawlProjectsByPagesCount(starCount);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    repositories.forEach(<span class="function"><span class="params">repository</span> =&gt;</span> repository.display());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> isSave = readlineSync.keyInYN(<span class="string">'请问是否要保存到本地(json 格式) ?'</span>);</span><br><span class="line">    isSave &amp;&amp; models.Repository.saveToLocal(repositories);</span><br><span class="line">    isContinue = readlineSync.keyInYN(<span class="string">'继续还是退出 ?'</span>);</span><br><span class="line">  &#125; <span class="keyword">while</span> (isContinue);</span><br><span class="line">  logger.info(<span class="string">'程序正常退出...'</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure><h3 id="来看看最后的效果"><a href="#来看看最后的效果" class="headerlink" title="来看看最后的效果"></a>来看看最后的效果</h3><p>这里要提一下 readline-sync 的一个 bug,，在 windows 上, vscode 中使用 git bash 时，中文会乱码，无论你文件格式是不是 utf-8。搜了一些 issues， 在 powershell 中切换编码为 utf-8 就可以正常显示，也就是把页码切到 <code>65001</code>。</p><p><img data-src="https://i.loli.net/2019/04/05/5ca71256f4137.png" alt="example"></p><p><img data-src="https://i.loli.net/2019/04/05/5ca711441ccb8.png" alt="repositories-json"></p><p>项目的完整源代码以及后续的教程源代码都会保存在我的 github 仓库: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RqeDY2Ni9TcGlkZXJz" title="https://github.com/tjx666/Spiders">Spiders<i class="fa fa-external-link"></i></span>。如果我的教程对您有帮助，希望不要吝啬您的 star 😊。后续的教程可能就是一个更复杂的案例，通过分析 ajax 请求来直接访问接口。</p></div><p style="text-align:center">（完）</p><footer class="post-footer"><div class="post-tags"><a href="/tags/node/" rel="tag"><i class="fa fa-tag"></i> node</a> <a href="/tags/spider/" rel="tag"><i class="fa fa-tag"></i> spider</a> <a href="/tags/github/" rel="tag"><i class="fa fa-tag"></i> github</a></div><div class="post-nav"><div class="post-nav-item"><a href="/%E6%80%BB%E7%BB%93%E4%B8%8B-javascript-%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="prev" title="总结下 javascript 中的一些小技巧"><i class="fa fa-chevron-left"></i> 总结下 javascript 中的一些小技巧</a></div><div class="post-nav-item"><a href="/%E8%B6%85%E5%AE%9E%E7%94%A8%E7%9A%84%20chrome%20%E6%89%A9%E5%B1%95%E6%8E%A8%E8%8D%90/" rel="next" title="超实用的 chrome 扩展推荐">超实用的 chrome 扩展推荐 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><script>window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#分析需求"><span class="nav-number">1.</span> <span class="nav-text">分析需求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#动手来实现这个小爬虫"><span class="nav-number">2.</span> <span class="nav-text">动手来实现这个小爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#获取源代码"><span class="nav-number">2.1.</span> <span class="nav-text">获取源代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解析源代码获取项目信息"><span class="nav-number">2.2.</span> <span class="nav-text">解析源代码获取项目信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#让爬虫项目更人性化"><span class="nav-number">2.3.</span> <span class="nav-text">让爬虫项目更人性化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#来看看最后的效果"><span class="nav-number">2.4.</span> <span class="nav-text">来看看最后的效果</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="余腾靖" src="/images/avatar.png"><p class="site-author-name" itemprop="name">余腾靖</p><div class="site-description" itemprop="description">总结和分享我的所学所思</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">15</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">5</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS95dS10ZW5nLWppbmcvYWN0aXZpdGllcw==" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yu-teng-jing&#x2F;activities"><i class="fa fa-fw fa-bookmark"></i>知乎</span> </span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vdXNlci81YWQwZGNhYTZmYjlhMDI4ZDkzNzk0Yjk=" title="掘金 → https:&#x2F;&#x2F;juejin.im&#x2F;user&#x2F;5ad0dcaa6fb9a028d93794b9"><i class="fa fa-fw fa-book"></i>掘金</span> </span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RqeDY2Ng==" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;tjx666"><i class="fa fa-fw fa-github"></i>GitHub</span> </span><span class="links-of-author-item"><span class="exturl" data-url="bWFpbHRvOnl0ajI3MTMxNTE3MTNAZ21haWwuY29t" title="E-Mail → mailto:ytj2713151713@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span> </span><span class="links-of-author-item"><a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-fw fa-rss"></i>RSS</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">余腾靖</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/js/local-search.js"></script><script>if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme: 'forest',
      logLevel: 3,
      flowchart: { curve: 'linear' },
      gantt: { axisFormat: '%m/%d/%Y' },
      sequence: { actorMargin: 50 }
    });
  }, window.mermaid);
}</script></body></html>